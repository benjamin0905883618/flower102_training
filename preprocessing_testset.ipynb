{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu May 25 11:28:18 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  Off  | 00000000:2B:00.0  On |                  N/A |\n",
      "| 46%   52C    P8    42W / 350W |    332MiB / 24576MiB |      4%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      1876      G   /usr/lib/xorg/Xorg                207MiB |\n",
      "|    0   N/A  N/A      2624      G   /usr/bin/gnome-shell               53MiB |\n",
      "|    0   N/A  N/A    801212      G   ...757444770829902008,262144       66MiB |\n",
      "+-----------------------------------------------------------------------------+\n",
      "CUDA Available :  True\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "# import package\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import DataLoader, ConcatDataset\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "import torchvision.utils as vutils\n",
    "from torchvision.datasets import DatasetFolder \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from RealESRGAN import RealESRGAN\n",
    "import os\n",
    "import torchattacks\n",
    "from models_c import *\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "\n",
    "# for denoise\n",
    "from utils import utils_logger\n",
    "from utils import utils_model\n",
    "from utils import utils_image as util\n",
    "from collections import OrderedDict\n",
    "\n",
    "# check CUDA status\n",
    "!nvidia-smi\n",
    "print(\"CUDA Available : \", torch.cuda.is_available())\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "noise_color = 'w'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "\n",
    "train_tfm = transforms.Compose([\n",
    "    transforms.RandomCrop((256, 256)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "toPillow = transforms.ToPILImage()\n",
    "totensor = transforms.ToTensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load model : flower102\n"
     ]
    }
   ],
   "source": [
    "model = models.densenet201(weights='DenseNet201_Weights.DEFAULT')\n",
    "model = nn.Sequential(*list(model.children())[:-1],ClassifierH2())\n",
    "model = model.to(device)\n",
    "checkpoint = torch.load(f'./pretrain/flower102_2023052039.pt')\n",
    "model.load_state_dict(checkpoint)\n",
    "model.eval()  \n",
    "print('load model : flower102')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Debugger :  class -> idx \n",
      "{'0': 0, '1': 1, '2': 2, '3': 3, '4': 4, '5': 5, '6': 6, '7': 7, '8': 8, '9': 9, '10': 10, '11': 11, '12': 12, '13': 13, '14': 14, '15': 15, '16': 16, '17': 17, '18': 18, '19': 19, '20': 20, '21': 21, '22': 22, '23': 23, '24': 24, '25': 25, '26': 26, '27': 27, '28': 28, '29': 29, '30': 30, '31': 31, '32': 32, '33': 33, '34': 34, '35': 35, '36': 36, '37': 37, '38': 38, '39': 39, '40': 40, '41': 41, '42': 42, '43': 43, '44': 44, '45': 45, '46': 46, '47': 47, '48': 48, '49': 49, '50': 50, '51': 51, '52': 52, '53': 53, '54': 54, '55': 55, '56': 56, '57': 57, '58': 58, '59': 59, '60': 60, '61': 61, '62': 62, '63': 63, '64': 64, '65': 65, '66': 66, '67': 67, '68': 68, '69': 69, '70': 70, '71': 71, '72': 72, '73': 73, '74': 74, '75': 75, '76': 76, '77': 77, '78': 78, '79': 79, '80': 80, '81': 81, '82': 82, '83': 83, '84': 84, '85': 85, '86': 86, '87': 87, '88': 88, '89': 89, '90': 90, '91': 91, '92': 92, '93': 93, '94': 94, '95': 95, '96': 96, '97': 97, '98': 98, '99': 99, '100': 100, '101': 101}\n"
     ]
    }
   ],
   "source": [
    "test_set = DatasetFolder('flower102/test', loader=lambda x: Image.open(x), extensions=\"jpg\", transform = train_tfm)\n",
    "\n",
    "test_loader = DataLoader(test_set, batch_size=32, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def denoise(imgs, model_name = 'drunet_color',x8 = False, show_img = False, border = 0, n_channels = 3, model_pool = 'denoise_model'):\n",
    "    # set params\n",
    "    noise_level_model = 15\n",
    "    model_name = model_name\n",
    "    testset_name = 'bsd68'\n",
    "\n",
    "    #set result path\n",
    "    results = 'results'                  # fixed\n",
    "    task_current = 'dn'                  # 'dn' for denoising\n",
    "    result_name = testset_name + '_' + task_current + '_' + model_name\n",
    "    model_path = os.path.join(model_pool, model_name+'.pth')\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    # initial model\n",
    "    from models_c.network_unet import UNetRes as net\n",
    "    model = net(in_nc=n_channels+1, out_nc=n_channels, nc=[64, 128, 256, 512], nb=4, act_mode='R', downsample_mode=\"strideconv\", upsample_mode=\"convtranspose\")\n",
    "    model.load_state_dict(torch.load(model_path), strict=True)\n",
    "    model.eval()\n",
    "    for k, v in model.named_parameters():\n",
    "        v.requires_grad = False\n",
    "    model = model.to(device)\n",
    "    number_parameters = sum(map(lambda x: x.numel(), model.parameters()))\n",
    "\n",
    "    # params show\n",
    "    test_results = OrderedDict()\n",
    "    test_results['psnr'] = []\n",
    "    test_results['ssim'] = []\n",
    "        \n",
    "    img = toPillow(imgs)\n",
    "    img.save('mask/2.bmp')\n",
    "    img_H = util.imread_uint(\"mask/2.bmp\", n_channels=n_channels)\n",
    "    img_L = util.uint2single(img_H)\n",
    "    #print(img_H.shape)\n",
    "    # Add noise without clipping\n",
    "    np.random.seed(seed=0)  # for reproducibility\n",
    "    img_L += np.random.normal(0, noise_level_model/255., img_L.shape)\n",
    "\n",
    "    util.imshow(util.single2uint(img_L), title='Noisy image with noise level {}'.format(noise_level_model)) if show_img else None\n",
    "\n",
    "    img_L = util.single2tensor4(img_L)\n",
    "    img_L = torch.cat((img_L, torch.FloatTensor([noise_level_model/255.]).repeat(1, 1, img_L.shape[2], img_L.shape[3])), dim=1)\n",
    "    #print(img_L.shape)\n",
    "    img_L = img_L.to(device)\n",
    "        \n",
    "        #print(img_L.size(2), img_L.size(3))\n",
    "\n",
    "    if not x8 and img_L.size(2)//8==0 and img_L.size(3)//8==0:\n",
    "        img_E = model(img_L)\n",
    "    elif not x8 and (img_L.size(2)//8!=0 or img_L.size(3)//8!=0):\n",
    "        img_E = utils_model.test_mode(model, img_L, refield=64, mode=5)\n",
    "    elif x8:\n",
    "        img_E = utils_model.test_mode(model, img_L, mode=3)\n",
    "\n",
    "    img_E = util.tensor2uint(img_E)\n",
    "    #print(img_E.shape)\n",
    "\n",
    "    if n_channels == 1:\n",
    "        img_H = img_H.squeeze() \n",
    "    psnr = util.calculate_psnr(img_E, img_H, border=border)\n",
    "    ssim = util.calculate_ssim(img_E, img_H, border=border)\n",
    "    test_results['psnr'].append(psnr)\n",
    "    test_results['ssim'].append(ssim)\n",
    "\n",
    "    util.imsave(img_E, \"mask/3.bmp\")\n",
    "        \n",
    "    img_after = Image.open(\"mask/3.bmp\")\n",
    "    img_after = totensor(img_after)\n",
    "    imgs = img_after\n",
    "\n",
    "    ave_psnr = sum(test_results['psnr']) / len(test_results['psnr'])\n",
    "    ave_ssim = sum(test_results['ssim']) / len(test_results['ssim'])\n",
    "    #print('Average PSNR/SSIM(RGB) - {} - PSNR: {:.2f} dB; SSIM: {:.4f}'.format(result_name, ave_psnr, ave_ssim))\n",
    "\n",
    "    return imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "def randomNoise(e, imgs):\n",
    "    for i in range(imgs.shape[0]):\n",
    "        img = imgs[i]\n",
    "        mask = torch.zeros((img.shape[0], img.shape[1], img.shape[2])).to(device)\n",
    "        points = []\n",
    "        #print(mask.shape, img.shape)\n",
    "        for k in range(e):\n",
    "            m_i = int(np.random.uniform(0, img.shape[1])) \n",
    "            m_j = int(np.random.uniform(0, img.shape[2]))\n",
    "            mask[:, m_j, m_i] = img[:, m_j, m_i]\n",
    "            points.append([m_j, m_i])\n",
    "            img[0, m_j, m_i] = (1 if noise_color == 'w' else 25/255)\n",
    "            img[1, m_j, m_i] = (1 if noise_color == 'w' else 20/255)\n",
    "            img[2, m_j, m_i] = (1 if noise_color == 'w' else 20/255)\n",
    "        new_img = toPillow(mask)\n",
    "        new_img.save('mask/0.bmp')\n",
    "        img = denoise(img).to(device)\n",
    "        for point in points:\n",
    "            img[:, point[0], point[1]] = mask[:, point[0], point[1]]\n",
    "        imgs[i] = img\n",
    "    return imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [04:02<00:00,  9.34s/it]\n"
     ]
    }
   ],
   "source": [
    "# import model\n",
    "\n",
    "path = f'flower102_test_set_{noise_color}'\n",
    "\n",
    "if not os.path.isdir(path):\n",
    "    os.mkdir(path)\n",
    "\n",
    "idx = 0\n",
    "\n",
    "for batch in tqdm(test_loader):\n",
    "    imgs, labels = batch\n",
    "    imgs, labels = imgs.to(device), labels.to(device)\n",
    "    \n",
    "    imgs = randomNoise(98, imgs)\n",
    "    #imgs = denoise(imgs)\n",
    "    for i in range(imgs.shape[0]):\n",
    "        img = imgs[i]\n",
    "        new_img = toPillow(img).convert('RGB')\n",
    "        if not os.path.isdir(path + '/' + str(int(labels[i]))):\n",
    "            os.mkdir(path + '/' + str(int(labels[i])) + '/')\n",
    "        new_img.save(path + '/' + str(int(labels[i])) + '/preprocess_' + str(idx) + '.jpg')\n",
    "        idx += 1\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [06:03<00:00, 13.96s/it]\n"
     ]
    }
   ],
   "source": [
    "# import model\n",
    "from tqdm import tqdm\n",
    "\n",
    "path = f'flower_test_adv_set_{noise_color}'\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "pgd_attack = torchattacks.PGD(model, eps=8/255, steps = 40)\n",
    "\n",
    "#adversary = LinfPGDAttack(model)\n",
    "\n",
    "if not os.path.isdir(path):\n",
    "    os.mkdir(path)\n",
    "\n",
    "idx = 0\n",
    "\n",
    "#test = True\n",
    "for batch in tqdm(test_loader):\n",
    "    imgs, labels = batch\n",
    "    imgs, labels = imgs.to(device), labels.to(device)\n",
    "    imgs = pgd_attack(imgs, labels)\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    imgs = randomNoise(98, imgs)\n",
    "    #imgs = denoise(imgs)\n",
    "    for i in range(imgs.shape[0]):\n",
    "        img = imgs[i]\n",
    "        new_img = toPillow(img)\n",
    "        if not os.path.isdir(path + '/' + str(int(labels[i]))):\n",
    "            os.mkdir(path + '/' + str(int(labels[i])) + '/')\n",
    "        new_img.save(path + '/' + str(int(labels[i])) + '/adv_' + str(idx) + '.jpg')\n",
    "        idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
